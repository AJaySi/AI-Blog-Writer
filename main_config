###################################################
#
# Define Blog Content charateristics:
# This is the main config file which drives the code.
# This config will restrict code modifications and hence ease of usuability.
#
###################################################

# Length of blogs Or word count. Note: It wont be exact and depends on GPT providers and Max token count.
blog_length = 2000

# professional, how-to, begginer, research, programming, casual, etc
blog_tone = "professional"

# Target Audience, Gen-Z, Tech-savvy, Working professional, students, kids etc
blog_demographic = "All"

# informational, commercial, company, news, finance, competitor, programming, scholar etc
blog_type = "Informational"

# German, Chinese, Arabic, Nepali, Hindi, Hindustani etc
blog_language = "English"

# Specify the output format of the blog as: HTML, markdown, plaintext. Defaults to markdown.
blog_output_format = "markdown"

# Specify full path to folder where the final blog should be stored. ex: _posts
blog_output_folder = ""

# Specify full path to folder where blog images will be stored. ex: assets
blog_image_output_folder = ""


############################################################
#
# Blog Images details.
# Note: The images are created from the blog content. Blog title is used,
# the title is modified for image generation prompt.
#
############################################################

# Options are dalle2, dalle3, stable-diffusion.
image_gen_model = "stable-diffusion"

# Number of blog images to include.
num_images = 1


###########################################################
#
# Define LLM and its charateristics for fine control on output
# Note: 
###########################################################

# Choose one of following: Openai, Google, Minstral
gpt_provider = "openai"

# Mention which model of the above provider to use.
model="gpt-3.5-turbo-0125"

# Temperature is a parameter that controls the “creativity” or randomness of the text generated by GPT.
# greater determinism and higher values indicating more randomness.
# while a lower temperature (e.g., 0.2) makes the output more deterministic and focused (thus, getting flagged as AI content).
temperature = 0.6


top_p=0.9 
max_tokens=4096
n=1


